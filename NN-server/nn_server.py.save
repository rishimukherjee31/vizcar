from flask import Flask, Response, jsonify, request
from flask_cors import CORS
import cv2
import numpy as np
from ultralytics import YOLO
import threading
import time
import logging
from collections import deque
from datetime import datetime
import json

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

app = Flask(__name__)
CORS(app)  # Enable CORS for cross-origin requests

class YOLOPoseProcessor:
	def __init__(self, source_url, model_name="best.pt"):
		self.source_url = source_url
        	self.model_name = model_name
        	self.model = None	

		# frame storage
        	self.current_frame = None
        	self.annotated_frame = None
        	self.frame_lock = threading.Lock()
        
        	# results storage
        	self.latest_results = None
        	self.results_lock = threading.Lock()
        	self.results_history = deque(maxlen=30) 

		# logging
		self.running = False
        	self.processing_thread = None
        	self.fps = 0
        	self.frame_count = 0
        	self.last_fps_update = time.time()
		self.inference_time = 0
        	self.total_inference_time = 0
        	self.total_frames_processed = 0

	def initialize_model(self):
        		import torch
            if torch.cuda.is_available():
                logger.info(f"✓ CUDA available - GPU: {torch.cuda.get_device_name(0)}")
                logger.info(f"✓ CUDA version: {torch.version.cuda}")
            else:
                logger.warning("⚠ CUDA not available, using CPU (will be slow)")

            logger.info("Model loaded successfully")
            return True

        except Exception
"""Load YOLO model"""
        try:
            logger.info(f"Loading YOLO model: {self.model_name}")
            self.model = YOLO(self.model_name)
            
            # Verify CUDA is available
            import torch
            if torch.cuda.is_available():
                logger.info(f"✓ CUDA available - GPU: {torch.cuda.get_device_name(0)}")
                logger.info(f"✓ CUDA version: {torch.version.cuda}")
            else:
                logger.warning("⚠ CUDA not available, using CPU (will be slow)")
            
            logger.info("Model loaded successfully")
            return True
            
        except Exception as e:
            logger.error(f"Failed to load model: {e}")
            return False
